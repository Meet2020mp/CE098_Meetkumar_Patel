{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNitkx7i/vOlPUR3EsTGS5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meet2020mp/ML_CE098_Meetkumar_Patel/blob/main/Lab12/ML_Lab12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oVw2--rg8mVn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(features_train, targets_train), (features_test,targets_test) = mnist.load_data()\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "n_iters = 5000\n",
        "log_interval = 10\n",
        "\n",
        "num_epochs = n_iters / (len(features_train) / batch_size_train)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "lyXA_ExK-T_8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "trainset = datasets.MNIST('/Lab12', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('/Lab12', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "sDbjFl1pQFEw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "      super(ANNModel, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "      self.dropout1 = nn.Dropout2d(0.25)\n",
        "      self.dropout2 = nn.Dropout2d(0.5)\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    # x represents our data\n",
        "  def forward(self, x):\n",
        "      # Pass data through conv1\n",
        "      x = self.conv1(x)\n",
        "      # Use the rectified-linear activation function over x\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      # Run max pooling over x\n",
        "      x = F.max_pool2d(x, 2)\n",
        "      # Pass data through dropout1\n",
        "      x = self.dropout1(x)\n",
        "      # Flatten x with start_dim=1\n",
        "      x = torch.flatten(x, 1)\n",
        "      # Pass data through fc1\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # Apply softmax to x\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output\n",
        "\n",
        "\n",
        "  # instantiate ANN\n",
        "input_dim = 28*28\n",
        "hidden_dim = 150 \n",
        "output_dim = 10\n",
        "\n",
        "# Create ANN\n",
        "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# SGD Optimizer\n",
        "learning_rate = 0.02\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "PlL-6dX9-2_S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)"
      ],
      "metadata": {
        "id": "MNgy-mPNSjN-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from time import time\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "# time0 = time()\n",
        "# epochs = 15\n",
        "# for e in range(epochs):\n",
        "#     running_loss = 0\n",
        "#     for images, labels in trainloader:\n",
        "#         # Flatten MNIST images into a 784 long vector\n",
        "#         images = images.view(images.shape[0], -1)\n",
        "    \n",
        "#         # Training pass\n",
        "#         optimizer.zero_grad()\n",
        "        \n",
        "#         output = model(images)\n",
        "#         loss = criterion(output, labels)\n",
        "        \n",
        "#         #This is where the model learns by backpropagating\n",
        "#         loss.backward()\n",
        "        \n",
        "#         #And optimizes its weights here\n",
        "#         optimizer.step()\n",
        "        \n",
        "#         running_loss += loss.item()\n",
        "#     else:\n",
        "#         print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "# print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "metadata": {
        "id": "ztVPceFLPyNo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "    flatten_data=[]\n",
        "    for i in range(len(X_data)):\n",
        "        sample=X_data[i]\n",
        "        flatten_row=[]\n",
        "        for row in sample:\n",
        "            flatten_row+=list(row)\n",
        "        flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    return np.array(flatten_data)\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def predict(self,x):\n",
        "        output=self.forward(x).tolist()[0]\n",
        "        lbl=output.index(max(output))\n",
        "        return lbl\n",
        "        pass\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:200]\n",
        "y_train=y_train[0:200]\n",
        "\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "y_train=torch.tensor(y_train)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 10\n",
        "n_iters = 5000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"Number Of Epochs : \",num_epochs)\n",
        "trainset=TensorDataset(X_train,y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    inputs = Variable(images.view(-1, input_dim))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pass\n",
        "  pass\n",
        "\n",
        "\n",
        "sample=torch.tensor(flatten([sample_image_mat]))\n",
        "print(\"prediction :\",model.predict(sample))\n",
        "# y_pred=torch.tensor(model.predict(X_test))\n",
        "# print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "L381ovgfrdtI",
        "outputId": "9182040c-0256-4b69-de6f-abfcf152c0c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "Number Of Epochs :  250\n",
            "prediction : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "  flatten_data=[]\n",
        "  for i in range(len(X_data)):\n",
        "    sample=X_data[i]\n",
        "    flatten_row=[]\n",
        "    for row in sample:\n",
        "      flatten_row+=list(row)\n",
        "      pass\n",
        "    pass\n",
        "    flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    pass\n",
        "  return np.array(flatten_data)\n",
        "  pass\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "y_train=y_train[0:100]\n",
        "\n",
        "# visualize one of the images in data set\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "\n",
        "y_train=torch.tensor(y_train)\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 5000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "trainset=np.array(list(zip(X_train,y_train)))\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "755zcfXIrf1w",
        "outputId": "e2f9056d-504b-4015-ca58-f701091a9baf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_epochs :  5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-6aee907deba0>:55: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n",
            "<ipython-input-19-6aee907deba0>:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "    flatten_data=[]\n",
        "    for i in range(len(X_data)):\n",
        "        sample=X_data[i]\n",
        "        flatten_row=[]\n",
        "        for row in sample:\n",
        "            flatten_row+=list(row)\n",
        "        flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    return np.array(flatten_data)\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def predict(self,x):\n",
        "        \n",
        "        output=self.forward(x).tolist()\n",
        "        output_labels=[]\n",
        "        for elem in output : \n",
        "          lbl=elem.index(max(elem))\n",
        "          output_labels.append(lbl)\n",
        "        output_labels=np.array(output_labels)\n",
        "        return output_labels\n",
        "        pass\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "X_test=X_test[0:100]\n",
        "y_train=y_train[0:100]\n",
        "y_test=y_test[0:100]\n",
        "\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "X_test=flatten(X_test)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "X_test=torch.tensor(X_test)\n",
        "y_train=torch.tensor(y_train)\n",
        "y_test=torch.tensor(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 10\n",
        "n_iters = 10000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "trainset=TensorDataset(X_train,y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim1 = 10\n",
        "hidden_dim2 = 10\n",
        "output_dim = 10\n",
        "\n",
        "model = ANNModel(input_dim, hidden_dim1,hidden_dim2, output_dim)\n",
        "\n",
        "criterion=nn.MSELoss()\n",
        "\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    inputs = Variable(images.view(-1, input_dim))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs=model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.step()\n",
        "    pass\n",
        "  pass\n",
        "\n",
        "\n",
        "sample=torch.tensor(flatten([sample_image_mat]))\n",
        "print(model.predict(sample))\n",
        "# y_pred=torch.tensor(model.predict(X_test))\n",
        "# print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "5tSljv5BraLB",
        "outputId": "8b0d3fd4-6881-4885-e542-5d253b815ab7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "num_epochs :  1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    }
  ]
}